{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS M152A MNIST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, autograd\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Data normalization transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load MNIST\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_compressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, 4, stride = 4)\n",
    "        self.conv1.weight.data.fill_(1/16)\n",
    "        self.conv1.bias.data.fill_(0)\n",
    "    def forward(self, x):\n",
    "        m = nn.ConstantPad2d(2, -1)\n",
    "        x = self.conv1(m(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 100\n",
    "n_output = 10\n",
    "n_input = 64\n",
    "classifier = nn.Sequential(nn.Linear(n_input, n_hidden),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(n_hidden, n_output),\n",
    "                           nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7043219628745813\n",
      "Training loss: 0.4779470110975349\n",
      "Training loss: 0.4308671415296953\n",
      "Training loss: 0.40998201258083394\n",
      "Training loss: 0.3964635702147921\n"
     ]
    }
   ],
   "source": [
    "mnist_compression = MNIST_compressor()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.003)\n",
    "t = torch.Tensor([-0.5])\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = mnist_compression(images).detach()\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images = (images > t).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# imagenum = 8\n",
    "# images, labels = next(iter(trainloader))\n",
    "\n",
    "# images = mnist_compression(images).detach()\n",
    "# images = images.view(images.shape[0], -1)\n",
    "# images = (images > t).float()\n",
    "# img = images[imagenum].view(1, 64)\n",
    "# print(labels[imagenum])\n",
    "\n",
    "# # Turn off gradients to speed up this part\n",
    "# with torch.no_grad():\n",
    "#     logps = classifier(img)\n",
    "\n",
    "# # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "# ps = torch.exp(logps)\n",
    "# plt.imshow(img.view(1, 8, 8).numpy().squeeze())\n",
    "# print(ps)\n",
    "\n",
    "classifier2 = nn.Sequential(nn.Linear(n_input, n_hidden),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(n_hidden, n_output))\n",
    "classifier2[0].weight.data = torch.round(classifier[0].weight*100)\n",
    "classifier2[2].weight.data = torch.round(classifier[2].weight*100)\n",
    "classifier2[0].bias.data = torch.round(classifier[0].bias * 100)\n",
    "classifier2[2].bias.data = torch.round(classifier[2].bias * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f816ad83da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 247
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "imagenum = 8\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = mnist_compression(images).detach()\n",
    "images = images.view(images.shape[0], -1)\n",
    "images = (images > t).float()\n",
    "img = images[imagenum].view(1, 64)\n",
    "print(labels[imagenum])\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    activations = classifier2(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "values, indices = torch.max(activations, 1)\n",
    "print(indices)\n",
    "plt.imshow(img.view(1, 8, 8).numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('input2hidden', classifier2[0].weight.data.numpy().astype(int), fmt='%-1.2i',delimiter='\\n', newline='\\n')\n",
    "np.savetxt('hidden2output', classifier2[2].weight.data.numpy().astype(int), fmt='%-1.2i',delimiter='\\n', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('input2hidden_bias', classifier2[0].bias.data.numpy().astype(int), fmt='%-1.2i', delimiter='\\n', newline='\\n')\n",
    "np.savetxt('hidden2output_bias', classifier2[2].bias.data.numpy().astype(int), fmt='%-1.2i', delimiter='\\n', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import Bits\n",
    "\n",
    "\n",
    "def convert_to_9bit_2s_complement(filename, line_length):\n",
    "    input = open(filename, 'r')\n",
    "    output = open(filename + '_b', 'w')\n",
    "    i = 0\n",
    "    for line in input:\n",
    "        if(i >= line_length):\n",
    "            output.write('\\n')\n",
    "            i=0\n",
    "        output.write(str(Bits(int=int(line), length=9).bin))\n",
    "        i+= 1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_9bit_2s_complement('hidden2output_bias', 1)\n",
    "convert_to_9bit_2s_complement('input2hidden_bias', 1)\n",
    "convert_to_9bit_2s_complement('input2hidden', 64)\n",
    "convert_to_9bit_2s_complement('hidden2output', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
