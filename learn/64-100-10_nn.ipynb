{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS M152A MNIST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, autograd\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Data normalization transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load MNIST\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_compressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, 4, stride = 4)\n",
    "        self.conv1.weight.data.fill_(1/16)\n",
    "        self.conv1.bias.data.fill_(0)\n",
    "    def forward(self, x):\n",
    "        m = nn.ConstantPad2d(2, -1)\n",
    "        x = self.conv1(m(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 100\n",
    "n_output = 10\n",
    "n_input = 64\n",
    "classifier = nn.Sequential(nn.Linear(n_input, n_hidden),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(n_hidden, n_output),\n",
    "                           nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.70457278303246\n",
      "Training loss: 0.4779601678379309\n",
      "Training loss: 0.43135047845367686\n",
      "Training loss: 0.4096336956503295\n",
      "Training loss: 0.39603521257861335\n"
     ]
    }
   ],
   "source": [
    "mnist_compression = MNIST_compressor()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.003)\n",
    "t = torch.Tensor([-0.5])\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = mnist_compression(images).detach()\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images = (images > t).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# imagenum = 8\n",
    "# images, labels = next(iter(trainloader))\n",
    "\n",
    "# images = mnist_compression(images).detach()\n",
    "# images = images.view(images.shape[0], -1)\n",
    "# images = (images > t).float()\n",
    "# img = images[imagenum].view(1, 64)\n",
    "# print(labels[imagenum])\n",
    "\n",
    "# # Turn off gradients to speed up this part\n",
    "# with torch.no_grad():\n",
    "#     logps = classifier(img)\n",
    "\n",
    "# # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "# ps = torch.exp(logps)\n",
    "# plt.imshow(img.view(1, 8, 8).numpy().squeeze())\n",
    "# print(ps)\n",
    "\n",
    "classifier2 = nn.Sequential(nn.Linear(n_input, n_hidden),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(n_hidden, n_output))\n",
    "classifier2[0].weight.data = torch.round(classifier[0].weight*100)\n",
    "classifier2[2].weight.data = torch.round(classifier[2].weight*100)\n",
    "classifier2[0].bias.data = torch.round(classifier[0].bias * 100)\n",
    "classifier2[2].bias.data = torch.round(classifier[2].bias * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor([6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa835405208>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 247
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "imagenum = 8\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = mnist_compression(images).detach()\n",
    "images = images.view(images.shape[0], -1)\n",
    "images = (images > t).float()\n",
    "img = images[imagenum].view(1, 64)\n",
    "print(labels[imagenum])\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    activations = classifier2(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "values, indices = torch.max(activations, 1)\n",
    "print(indices)\n",
    "plt.imshow(img.view(1, 8, 8).numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('input2hidden', classifier2[0].weight.data.numpy().astype(int), fmt='%-1.2i',delimiter='\\n', newline='\\n')\n",
    "np.savetxt('hidden2output', classifier2[2].weight.data.numpy().astype(int), fmt='%-1.2i',delimiter='\\n', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('input2hidden_bias', classifier2[0].bias.data.numpy().astype(int), fmt='%-1.2i', delimiter='\\n', newline='\\n')\n",
    "np.savetxt('hidden2output_bias', classifier2[2].bias.data.numpy().astype(int), fmt='%-1.2i', delimiter='\\n', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import Bits\n",
    "\n",
    "\n",
    "def convert_to_9bit_2s_complement(filename):\n",
    "    input = open(filename, 'r')\n",
    "    output = open(filename + '_b', 'w')\n",
    "    for line in input:\n",
    "        output.write(str(Bits(int=int(line), length=9).bin) + '\\n')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished writing\n",
      "finished writing\n",
      "finished writing\n",
      "finished writing\n"
     ]
    }
   ],
   "source": [
    "convert_to_9bit_2s_complement('hidden2output_bias')\n",
    "convert_to_9bit_2s_complement('input2hidden_bias')\n",
    "convert_to_9bit_2s_complement('input2hidden')\n",
    "convert_to_9bit_2s_complement('hidden2output')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
