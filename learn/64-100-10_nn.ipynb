{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS M152A MNIST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, autograd\n",
    "import torch.nn.init\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Data normalization transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load MNIST\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_compressor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 1, 4, stride = 4)\n",
    "        self.conv1.weight.data.fill_(1/16)\n",
    "        self.conv1.bias.data.fill_(0)\n",
    "    def forward(self, x):\n",
    "        m = nn.ConstantPad2d(2, -1)\n",
    "        x = self.conv1(m(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 100\n",
    "n_output = 10\n",
    "n_input = 64\n",
    "classifier = nn.Sequential(nn.Linear(n_input, n_hidden),\n",
    "                           nn.ReLU(),\n",
    "                           nn.Linear(n_hidden, n_output),\n",
    "                           nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.7131873166828013\n",
      "Training loss: 0.47893573532798395\n",
      "Training loss: 0.4310781837526415\n",
      "Training loss: 0.40660534136648624\n",
      "Training loss: 0.393399220706621\n"
     ]
    }
   ],
   "source": [
    "mnist_compression = MNIST_compressor()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 5\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.003)\n",
    "t = torch.Tensor([-0.5])\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        images = mnist_compression(images).detach()\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        images = (images > t).float()\n",
    "        optimizer.zero_grad()\n",
    "        output = classifier(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "# imagenum = 8\n",
    "# images, labels = next(iter(trainloader))\n",
    "\n",
    "# images = mnist_compression(images).detach()\n",
    "# images = images.view(images.shape[0], -1)\n",
    "# images = (images > t).float()\n",
    "# img = images[imagenum].view(1, 64)\n",
    "# print(labels[imagenum])\n",
    "\n",
    "# # Turn off gradients to speed up this part\n",
    "# with torch.no_grad():\n",
    "#     logps = classifier(img)\n",
    "\n",
    "# # Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "# ps = torch.exp(logps)\n",
    "# plt.imshow(img.view(1, 8, 8).numpy().squeeze())\n",
    "# print(ps)\n",
    "\n",
    "classifier2 = nn.Sequential(nn.Linear(n_input, n_hidden),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(n_hidden, n_output))\n",
    "classifier2[0].weight.data = torch.round(classifier[0].weight*100)\n",
    "classifier2[2].weight.data = torch.round(classifier[2].weight*100)\n",
    "classifier2[0].bias.data = torch.round(classifier[0].bias * 100)\n",
    "classifier2[2].bias.data = torch.round(classifier[2].bias * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "tensor([7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x117100630>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 247
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "imagenum = 8\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "images = mnist_compression(images).detach()\n",
    "images = images.view(images.shape[0], -1)\n",
    "images = (images > t).float()\n",
    "img = images[imagenum].view(1, 64)\n",
    "print(labels[imagenum])\n",
    "\n",
    "# Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    activations = classifier2(img)\n",
    "\n",
    "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
    "values, indices = torch.max(activations, 1)\n",
    "print(indices)\n",
    "plt.imshow(img.view(1, 8, 8).numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('input2hidden', classifier2[0].weight.data.numpy().astype(int), fmt='%-1.2i',delimiter='\\n', newline='\\n')\n",
    "np.savetxt('hidden2output', classifier2[2].weight.data.numpy().astype(int), fmt='%-1.2i',delimiter='\\n', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('input2hidden_bias', classifier2[0].bias.data.numpy().astype(int), fmt='%-1.2i', delimiter='\\n', newline='\\n')\n",
    "np.savetxt('hidden2output_bias', classifier2[2].bias.data.numpy().astype(int), fmt='%-1.2i', delimiter='\\n', newline='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitstring import Bits\n",
    "\n",
    "\n",
    "def convert_to_9bit_2s_complement(filename, line_length):\n",
    "    input = open(filename, 'r')\n",
    "    output = open(filename + '_b', 'w')\n",
    "    i = 0\n",
    "    for line in input:\n",
    "        if(i >= line_length):\n",
    "            output.write('\\n')\n",
    "            i=0\n",
    "        output.write(str(Bits(int=int(line), length=9).bin))\n",
    "        i+= 1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_9bit_2s_complement('hidden2output_bias', 1)\n",
    "convert_to_9bit_2s_complement('input2hidden_bias', 1)\n",
    "convert_to_9bit_2s_complement('input2hidden', 64)\n",
    "convert_to_9bit_2s_complement('hidden2output', 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
